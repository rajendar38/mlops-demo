{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99b712-ba3b-48c8-85e5-9ea65976548f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade -q aiobotocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb0de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e2cd58-00b4-4a0f-8be5-b9174c420f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from io import StringIO\n",
    "import base64\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "sm_autoscaling_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# S3 locations used for parameterizing the notebook run\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\" \n",
    "model_prefix = \"models/xgb-fraud\"\n",
    "\n",
    "data_capture_key = f\"{write_prefix}/data-capture\"\n",
    "\n",
    "# S3 location of trained model artifact\n",
    "model_uri = f\"s3://{read_bucket}/{model_prefix}/fraud-det-xgb-model.tar.gz\"\n",
    "\n",
    "# S3 path where data captured at endpoint will be stored\n",
    "data_capture_uri = f\"s3://{write_bucket}/{data_capture_key}\"\n",
    "\n",
    "# S3 location of test data\n",
    "test_data_uri = f\"s3://{read_bucket}/{read_prefix}/test.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4118d5a5-941b-43a0-bcec-bdb898bd7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the SageMaker managed XGBoost image\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# Specify a unique model name that does not exist\n",
    "model_name = \"fraud-detect-xgb\"\n",
    "primary_container = {\n",
    "                     \"Image\": training_image,\n",
    "                     \"ModelDataUrl\": model_uri\n",
    "                    }\n",
    "\n",
    "model_matches = sm_client.list_models(NameContains=model_name)[\"Models\"]\n",
    "if not model_matches:\n",
    "    model = sm_client.create_model(ModelName=model_name,\n",
    "                                   PrimaryContainer=primary_container,\n",
    "                                   ExecutionRoleArn=sagemaker_role)\n",
    "else:\n",
    "    print(f\"Model with name {model_name} already exists! Change model name to create new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b99a333-81d5-42f9-8107-55773cd959be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Config name\n",
    "endpoint_config_name = f\"{model_name}-endpoint-config\"\n",
    "\n",
    "# Endpoint config parameters\n",
    "production_variant_dict = {\n",
    "                           \"VariantName\": \"Alltraffic\",\n",
    "                           \"ModelName\": model_name,\n",
    "                           \"InitialInstanceCount\": 1,\n",
    "                           \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                           \"InitialVariantWeight\": 1\n",
    "                          }\n",
    "\n",
    "# Data capture config parameters\n",
    "data_capture_config_dict = {\n",
    "                            \"EnableCapture\": True,\n",
    "                            \"InitialSamplingPercentage\": 100,\n",
    "                            \"DestinationS3Uri\": data_capture_uri,\n",
    "                            \"CaptureOptions\": [{\"CaptureMode\" : \"Input\"}, {\"CaptureMode\" : \"Output\"}]\n",
    "                           }\n",
    "\n",
    "\n",
    "# Create endpoint config if one with the same name does not exist\n",
    "endpoint_config_matches = sm_client.list_endpoint_configs(NameContains=endpoint_config_name)[\"EndpointConfigs\"]\n",
    "if not endpoint_config_matches:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "                                                                EndpointConfigName=endpoint_config_name,\n",
    "                                                                ProductionVariants=[production_variant_dict],\n",
    "                                                                DataCaptureConfig=data_capture_config_dict\n",
    "                                                               )\n",
    "else:\n",
    "\t\tprint(f\"Endpoint config with name {endpoint_config_name} already exists! Change endpoint config name to create new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db72666e-8e9f-4e18-b149-f589b69a02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Status: Creating...\n",
      "Endpoint Status: Creating...\n",
      "Endpoint Status: Creating...\n",
      "Endpoint Status: InService\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_matches = sm_client.list_endpoints(NameContains=endpoint_name)[\"Endpoints\"]\n",
    "if not endpoint_matches:\n",
    "    endpoint_response = sm_client.create_endpoint(\n",
    "                                                  EndpointName=endpoint_name,\n",
    "                                                  EndpointConfigName=endpoint_config_name\n",
    "                                                 )\n",
    "else:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists! Change endpoint name to create new\")\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Endpoint Status: {status}...\")\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd0a01-2dbd-4af3-854a-8df3ec8af6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch test data to run predictions with the endpoint\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "\n",
    "# For content type text/csv, payload should be a string with commas separating the values for each feature\n",
    "# This is the inference request serialization step\n",
    "# CSV serialization\n",
    "csv_file = io.StringIO()\n",
    "test_sample = test_df.drop([\"fraud\"], axis=1).iloc[:5]\n",
    "test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "response = sm_runtime_client.invoke_endpoint(\n",
    "                                             EndpointName=endpoint_name,\n",
    "                                             Body=payload,\n",
    "                                             ContentType=\"text/csv\",\n",
    "                                             Accept=\"text/csv\"\n",
    "                                            )\n",
    "\n",
    "# This is the inference response deserialization step\n",
    "# This is a bytes object\n",
    "result = response[\"Body\"].read()\n",
    "# Decoding bytes to a string\n",
    "result = result.decode(\"utf-8\")\n",
    "# Converting to list of predictions\n",
    "result = re.split(\",|\\n\",result)\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df[\"Prediction\"] = result[:5]\n",
    "prediction_df[\"Label\"] = test_df[\"fraud\"].iloc[:5].values\n",
    "prediction_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14698853-0960-4108-8721-de5ad12617f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(90):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "print()\n",
    "print(f\"Found {len(capture_files)} Data Capture Files:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca6a88-880a-45c8-be7c-0f21a9ed85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "capture_file = S3Downloader.read_file(capture_files[0]).split(\"\\n\")\n",
    "capture_record = json.loads(capture_file[0])\n",
    "capture_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08504b81-2858-4de6-aa9c-d87123dfb6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
